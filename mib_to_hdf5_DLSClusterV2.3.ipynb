{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This script checks the folder that 4D-STEM data is being saved (user input, e.g. \\\\e02-storage\\data\\2018\\em19064-2\\Merlin). In case there \n",
    "#is a new dataset (assumes time-stamping folders to appear), it saves into the processing folder of the \n",
    "#corresponding visit, e.g.\\\\e02-storage\\data\\2018\\em19064-2\\processing the following files:\n",
    "# full data in hdf5 format\n",
    "# data binned by 4 (on diff plane) in hdf5 format\n",
    "# incoherent bright-field image (ibf) TIFF\n",
    "# sum diffraction pattern image TIFF\n",
    "\n",
    "# Note that if the time-stamped folder already exists in the Processing path, this code assumes that the conversion has\n",
    "# already been done!\n",
    "\n",
    "#TO DO:\n",
    "#Add peak finding routine\n",
    "#Ask User if they want ADF / BF images also saved\n",
    "#How to handle half-written files when automated?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hyperspy_gui_traitsui:The TkAgg matplotlib backend is not supported by the installed traitsui version and the ETS toolkit has been set to null. To set the ETS toolkit independently from the matplotlib backend, set it before importing matplotlib.\n",
      "WARNING:hyperspy_gui_traitsui:The traitsui GUI elements are not available.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "#This won't work with cluster\n",
    "import hyperspy.api as hs\n",
    "#import matplotlib \n",
    "#%matplotlib qt5\n",
    "#change to qt5 for the installed version on DLS Linux\n",
    "import numpy as np\n",
    "from math import floor\n",
    "import pylab as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Medipix acquisition folder path (use time-stamping): P:\\data\\2018\\em19064-2\\Merlin\\Medipix\n",
      "******************************\n",
      "Found session folder:  em19064-2\n",
      "Processed data will be saved at:  P:\\data\\2018\\em19064-2\\processing\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "acquisition_folder = input(\"Enter the Medipix acquisition folder path (use time-stamping): \")\n",
    "print('******************************')\n",
    "assert os.path.exists(acquisition_folder), \"We did not find the folder at, \"+str(acquisition_folder)\n",
    "#print('We found your Session folder!')\n",
    "path_count = 1\n",
    "acquisition_path = Path(acquisition_folder)\n",
    "for parts in acquisition_path.parts:\n",
    "    path_count +=1\n",
    "    if parts.startswith(('em','cm')):\n",
    "        print('Found session folder: ', parts)\n",
    "        processing_folder = str(acquisition_path.parents[len(acquisition_path.parts) - path_count])+ r'\\processing'\n",
    "        \n",
    "        try:\n",
    "            os.chdir(processing_folder)\n",
    "            #if it doesn't exist create it\n",
    "        except OSError:\n",
    "            #break\n",
    "            try: \n",
    "                os.makedirs(processing_folder)\n",
    "            except OSError:\n",
    "                if not os.path.isdir(processing_folder):\n",
    "                    raise\n",
    "            \n",
    "        print('Processed data will be saved at: ', processing_folder)\n",
    "        print('******************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_4DSTEM_data(data, plot_sum = False):\n",
    "    \"\"\"\n",
    "    Reshapes the lazy-imported stack of dimensions: (xxxxxx|256, 256) to the correct scan pattern shape: (x, y | 256,256)\n",
    "    It utilises the over-exposed fly-back frame to identify the start of the lines in the first 10 scan lines, \n",
    "    checks line length consistancy and finds the number of frames to skip at the beginning (this number is printed out as \n",
    "    string output).\n",
    "    Note that this code crops the over-exposed flyback pixel on the LHS of the frame. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : hyperspy lazily imported mib file with diensions of: framenumbers|256, 256\n",
    "       \n",
    "    Returns\n",
    "    -------\n",
    "    data_reshaped : reshaped data (x, y | 256,256)\n",
    "    optional: plots the sum intensity vs frames\n",
    "    \"\"\"\n",
    "    data_crop = data.inav[0:np.int(10* np.sqrt(data.axes_manager[0].size))] #crop the first ~10 lines\n",
    "    data_crop_t = data_crop.T\n",
    "    data_crop_t_sum = data_crop_t.sum()\n",
    "    intensity_array = data_crop_t_sum.data #summing over patterns\n",
    "    intensity_array = intensity_array.compute() #out of lazy\n",
    "    #Checking for local maxima to be more than 10 times the neighbouring elements\n",
    "    local_max = (np.r_[True, intensity_array[1:] > 10* intensity_array[:-1]] \n",
    "            & np.r_[intensity_array[:-1] > 10* intensity_array[1:], True])\n",
    "    \n",
    "    if plot_sum == True:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        fig1 = plt.figure()\n",
    "        ax1 = fig1.add_subplot(121)\n",
    "        ax2 = fig1.add_subplot(122)\n",
    "        \n",
    "        ax1.plot(intensity_array, 'k')\n",
    "        ax2.plot(local_max, 'b')\n",
    "        \n",
    "        ax1.set_title('sum intensity of first 2pct of frames')\n",
    "        ax2.set_title('peaks detected')\n",
    "    \n",
    "    peaks = np.ravel(np.where(local_max))\n",
    "    lines = np.ediff1d(peaks) #Diff between consecutive elements of the array\n",
    "    line_len = lines[lines.size-1] # Assuming the last element to be the line length\n",
    "    check = np.ravel(np.where(lines == line_len)) #Checking line lengths\n",
    "    \n",
    "    line_confirm = [np.ediff1d(check) == 1]\n",
    "    if ~np.all(line_confirm):\n",
    "        print('Line lengths are not consistent! Soemthing went wrong!')\n",
    "        return data\n",
    "\n",
    "    skip_ind = peaks[check[0]] #number of frames to skip at the beginning\n",
    "    \n",
    "    n_lines = floor((data.data.shape[0] - skip_ind) / line_len) #Number of lines\n",
    "    data_skip = data.inav[skip_ind:skip_ind + (n_lines * line_len)] #with the skipped frames removed\n",
    "    \n",
    "    data_skip.data = data_skip.data.reshape(n_lines, line_len, 256, 256)\n",
    "    data_skip.axes_manager._axes.insert(0, data_skip.axes_manager[0].copy())\n",
    "    data_skip.get_dimensions_from_data() #reshaped\n",
    "    \n",
    "    print('Number of frames skipped at the beginning: ', skip_ind)\n",
    "    data_skip = data_skip.inav[1:]\n",
    "    return data_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently active in this directory: 20180727 095242\n",
      "A5V33dT6-9cmCL-400kx.hdr\n",
      "P:\\data\\2018\\em19064-2\\Merlin\\Medipix\\20180727 095242\n",
      "\n",
      " ******* 20180727 095242 Folder already exists! *********\n",
      "Total time elapsed (seconds):  0\n",
      "Currently active in this directory: 20180727 150054\n",
      "G1HSA6iT6-9cmCL-4Mx.hdr\n",
      "P:\\data\\2018\\em19064-2\\Merlin\\Medipix\\20180727 150054\n",
      "loaded to hyperspy\n",
      "Number of frames skipped at the beginning:  673\n",
      "Data reshaped to: (511, 511)\n",
      "Saving the hdf5 version of G1HSA6iT6-9cmCL-4Mx.hdr\n",
      "Writing binned hdf5\n",
      "[########################################] | 100% Completed |  6min  0.4s\n",
      "Writing ibf tiff\n",
      "Writing sum diffraction tiff\n"
     ]
    }
   ],
   "source": [
    "##converts all mib files in folder to hdf5 and saves binned data and incoherent BF image\n",
    "os.chdir(acquisition_folder)\n",
    "for dirName in os.listdir(acquisition_folder):\n",
    "    time0 = time.time()\n",
    "    print('Currently active in this directory: %s' % dirName)\n",
    "    \n",
    "    for root, dirs, files in os.walk(acquisition_folder + '\\\\' + dirName, topdown = False):\n",
    "        for file_name in files:\n",
    "            #print(file_name)\n",
    "            if file_name.endswith('.hdr'):\n",
    "                print(file_name)\n",
    "                print(acquisition_folder + '\\\\' + dirName)\n",
    "                \n",
    "                #If the folder already exists assumes the hdf5 is already saved and moves on\n",
    "                if os.path.exists(processing_folder + r'\\\\' + dirName):\n",
    "                    print('\\n ******* ' + dirName + ' Folder already exists! *********')\n",
    "                else:\n",
    "                    os.chdir(acquisition_folder + '\\\\' + dirName)\n",
    "                    try:\n",
    "                        dp = hs.load(file_name, lazy = True)\n",
    "                    except ValueError:\n",
    "                        print('Something went wrong during acquisition!!!')\n",
    "                        break\n",
    "\n",
    "                    print('loaded to hyperspy')\n",
    "                    # checks to see if it is a multi-frame data before reshaping\n",
    "                    if any(dp.axes_manager.navigation_axes):\n",
    "                        dp = reshape_4DSTEM_data(dp)\n",
    "                        print('Data reshaped to: '+ str(dp.axes_manager.navigation_shape))\n",
    "                        #TODO peak finding + individual DF\n",
    "                        os.chdir(processing_folder)\n",
    "                        os.mkdir(dirName)\n",
    "                        os.chdir(processing_folder + r'\\\\' + dirName)\n",
    "                        #Only save if the dp object is from the right file! - Removing the extensions\n",
    "                        if dp.metadata.General.original_filename.rpartition('.')[0] == file_name.rpartition('.')[0]:\n",
    "                            print('Saving the hdf5 version of '+ file_name)\n",
    "                            dp.save(file_name, extension = 'hdf5')\n",
    "                        #Only save dp_bin and ibf if they exist! (not the case for single frame data)\n",
    "                        try:         \n",
    "                            print('Writing binned hdf5')\n",
    "                            #making a binned version\n",
    "                            dp_bin = dp.rebin(scale = (1,1,4,4))\n",
    "                            dp_bin.compute()\n",
    "                            file_bin = file_name.rpartition('.')[0]+ '_bin'\n",
    "                            dp_bin.save(file_bin, extension = 'hdf5')\n",
    "                            print('Writing ibf tiff')\n",
    "                            #making an ibf image\n",
    "                            ibf = dp_bin.sum(axis = dp_bin.axes_manager.signal_axes)\n",
    "                            ibf = ibf.T\n",
    "                            file_ibf = file_name.rpartition('.')[0]+ '_ibf'\n",
    "                            ibf.save(file_ibf, extension = 'tiff')\n",
    "                            print('Writing sum diffraction tiff')\n",
    "                            # sum dp image\n",
    "                            sum_dp = dp.sum(axis=dp.axes_manager.navigation_axes)\n",
    "                            file_dp = file_name.rpartition('.')[0]+ '_dp'\n",
    "                            sum_dp.save(file_dp, extension = 'tiff')\n",
    "                        except(NameError, ValueError):\n",
    "                            print('Something went wrong - perhaps data is a single frame!')\n",
    "            \n",
    "        print('Total time elapsed (seconds): ', int(time.time() - time0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
